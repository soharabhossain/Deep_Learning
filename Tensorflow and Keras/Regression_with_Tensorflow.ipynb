{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression_with_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLgxI6ZpIqLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543f6f69-1033-40bd-9e3c-077ec2cd725b"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWjqcVX4KTr2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "242f6e5d-0aef-4d8c-9741-152f71750eaa"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4rdoFFbE2en"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOXDagrbYb7v"
      },
      "source": [
        "## Custom Function for Generating Synthetic Data for Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W19v-uOaE7Yj"
      },
      "source": [
        "def generate_dataset():\n",
        " x_batch = np.linspace(0, 2, 100)\n",
        " x_batch.shape\n",
        " y_batch = 1.5 * x_batch + np.random.randn(x_batch.shape[0]) * 0.2 + 0.5\n",
        " return x_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK3JzrakX3Vm"
      },
      "source": [
        "## Custom function to build the Computation Graph for Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB3HPL3pFGGY"
      },
      "source": [
        "\n",
        "def linear_regression():\n",
        "\n",
        "  x = tf.placeholder(tf.float32, shape=(None, ), name='x')\n",
        "  y = tf.placeholder(tf.float32, shape=(None, ), name='y')\n",
        "\n",
        "  with tf.variable_scope('lreg') as scope:\n",
        "    w = tf.Variable(np.random.normal(), name='W')\n",
        "    b = tf.Variable(np.random.normal(), name='b')\n",
        "\t\t\n",
        "    y_pred = tf.add(tf.multiply(w, x), b)\n",
        "\n",
        "    loss = tf.reduce_mean(tf.square(y_pred - y))\n",
        "\n",
        "  return x, y, y_pred, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7hU05LIX-ZQ"
      },
      "source": [
        "## Define Placeholders for taking input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80TRP_-oFIci"
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=(None, ), name='x')  \n",
        "y = tf.placeholder(tf.float32, shape=(None, ), name='y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eITNDiuOYJJT"
      },
      "source": [
        "## Call the Custom Functions to Generate Data and Build the Computation Graph for Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1F5mFV5XP3k"
      },
      "source": [
        "x_batch, y_batch = generate_dataset()\n",
        "x, y, y_pred, loss = linear_regression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luRSzeGgYjka"
      },
      "source": [
        "## Define the Optimizer and associate the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvd2cyPZYGG1"
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
        "\n",
        "train_op = optimizer.minimize(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VGrq9bHYoH-"
      },
      "source": [
        "## Execute the Computation Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxrwK6zCLa83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c62235-4013-4d23-9739-bf5bec5a4b1a"
      },
      "source": [
        "with tf.Session() as session:\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  feed_dict = {x: x_batch, y: y_batch}\n",
        "\t\t\n",
        "  for i in range(300):\n",
        "    session.run(train_op, feed_dict)\n",
        "    print(i, \"loss:\", loss.eval(feed_dict))\n",
        "\n",
        "  # Prediction\n",
        "  y_pred_batch = session.run(y_pred, feed_dict ={x : x_batch})\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 loss: 1.7958221\n",
            "1 loss: 0.66857094\n",
            "2 loss: 0.30666903\n",
            "3 loss: 0.18773733\n",
            "4 loss: 0.14610885\n",
            "5 loss: 0.12923369\n",
            "6 loss: 0.12043331\n",
            "7 loss: 0.11440491\n",
            "8 loss: 0.109454006\n",
            "9 loss: 0.10503111\n",
            "10 loss: 0.100950524\n",
            "11 loss: 0.097142704\n",
            "12 loss: 0.09357544\n",
            "13 loss: 0.090229146\n",
            "14 loss: 0.0870887\n",
            "15 loss: 0.08414099\n",
            "16 loss: 0.08137407\n",
            "17 loss: 0.078776814\n",
            "18 loss: 0.076338746\n",
            "19 loss: 0.07405017\n",
            "20 loss: 0.07190187\n",
            "21 loss: 0.069885276\n",
            "22 loss: 0.06799231\n",
            "23 loss: 0.06621537\n",
            "24 loss: 0.06454738\n",
            "25 loss: 0.062981635\n",
            "26 loss: 0.06151189\n",
            "27 loss: 0.06013223\n",
            "28 loss: 0.058837153\n",
            "29 loss: 0.057621464\n",
            "30 loss: 0.056480292\n",
            "31 loss: 0.055409092\n",
            "32 loss: 0.054403562\n",
            "33 loss: 0.053459655\n",
            "34 loss: 0.052573632\n",
            "35 loss: 0.05174191\n",
            "36 loss: 0.05096118\n",
            "37 loss: 0.05022831\n",
            "38 loss: 0.04954037\n",
            "39 loss: 0.048894595\n",
            "40 loss: 0.048288427\n",
            "41 loss: 0.047719408\n",
            "42 loss: 0.047185265\n",
            "43 loss: 0.046683863\n",
            "44 loss: 0.046213206\n",
            "45 loss: 0.04577141\n",
            "46 loss: 0.045356687\n",
            "47 loss: 0.044967394\n",
            "48 loss: 0.044601955\n",
            "49 loss: 0.04425893\n",
            "50 loss: 0.043936923\n",
            "51 loss: 0.043634668\n",
            "52 loss: 0.04335093\n",
            "53 loss: 0.04308459\n",
            "54 loss: 0.042834587\n",
            "55 loss: 0.042599898\n",
            "56 loss: 0.042379603\n",
            "57 loss: 0.04217281\n",
            "58 loss: 0.0419787\n",
            "59 loss: 0.041796476\n",
            "60 loss: 0.041625433\n",
            "61 loss: 0.041464873\n",
            "62 loss: 0.04131416\n",
            "63 loss: 0.041172676\n",
            "64 loss: 0.041039877\n",
            "65 loss: 0.040915214\n",
            "66 loss: 0.04079819\n",
            "67 loss: 0.040688343\n",
            "68 loss: 0.040585227\n",
            "69 loss: 0.040488433\n",
            "70 loss: 0.040397577\n",
            "71 loss: 0.040312294\n",
            "72 loss: 0.04023223\n",
            "73 loss: 0.040157076\n",
            "74 loss: 0.04008653\n",
            "75 loss: 0.040020313\n",
            "76 loss: 0.039958153\n",
            "77 loss: 0.039899804\n",
            "78 loss: 0.03984502\n",
            "79 loss: 0.039793614\n",
            "80 loss: 0.039745346\n",
            "81 loss: 0.039700042\n",
            "82 loss: 0.03965752\n",
            "83 loss: 0.039617594\n",
            "84 loss: 0.039580118\n",
            "85 loss: 0.039544944\n",
            "86 loss: 0.039511923\n",
            "87 loss: 0.03948093\n",
            "88 loss: 0.039451838\n",
            "89 loss: 0.039424524\n",
            "90 loss: 0.039398894\n",
            "91 loss: 0.03937482\n",
            "92 loss: 0.039352227\n",
            "93 loss: 0.039331023\n",
            "94 loss: 0.039311115\n",
            "95 loss: 0.039292432\n",
            "96 loss: 0.039274894\n",
            "97 loss: 0.039258424\n",
            "98 loss: 0.03924297\n",
            "99 loss: 0.03922846\n",
            "100 loss: 0.039214846\n",
            "101 loss: 0.03920206\n",
            "102 loss: 0.039190065\n",
            "103 loss: 0.0391788\n",
            "104 loss: 0.039168224\n",
            "105 loss: 0.039158303\n",
            "106 loss: 0.03914898\n",
            "107 loss: 0.03914024\n",
            "108 loss: 0.03913203\n",
            "109 loss: 0.03912432\n",
            "110 loss: 0.039117087\n",
            "111 loss: 0.0391103\n",
            "112 loss: 0.03910393\n",
            "113 loss: 0.03909794\n",
            "114 loss: 0.03909232\n",
            "115 loss: 0.039087042\n",
            "116 loss: 0.0390821\n",
            "117 loss: 0.039077453\n",
            "118 loss: 0.039073095\n",
            "119 loss: 0.039068993\n",
            "120 loss: 0.039065156\n",
            "121 loss: 0.039061543\n",
            "122 loss: 0.039058164\n",
            "123 loss: 0.039054986\n",
            "124 loss: 0.039052\n",
            "125 loss: 0.039049197\n",
            "126 loss: 0.03904657\n",
            "127 loss: 0.039044097\n",
            "128 loss: 0.039041787\n",
            "129 loss: 0.039039616\n",
            "130 loss: 0.039037574\n",
            "131 loss: 0.039035663\n",
            "132 loss: 0.039033853\n",
            "133 loss: 0.039032172\n",
            "134 loss: 0.039030578\n",
            "135 loss: 0.03902909\n",
            "136 loss: 0.039027702\n",
            "137 loss: 0.039026383\n",
            "138 loss: 0.039025158\n",
            "139 loss: 0.039024003\n",
            "140 loss: 0.039022915\n",
            "141 loss: 0.0390219\n",
            "142 loss: 0.039020944\n",
            "143 loss: 0.039020047\n",
            "144 loss: 0.03901921\n",
            "145 loss: 0.03901842\n",
            "146 loss: 0.039017674\n",
            "147 loss: 0.039016977\n",
            "148 loss: 0.039016325\n",
            "149 loss: 0.039015714\n",
            "150 loss: 0.039015137\n",
            "151 loss: 0.039014596\n",
            "152 loss: 0.039014086\n",
            "153 loss: 0.03901361\n",
            "154 loss: 0.039013162\n",
            "155 loss: 0.03901274\n",
            "156 loss: 0.03901235\n",
            "157 loss: 0.039011978\n",
            "158 loss: 0.03901163\n",
            "159 loss: 0.039011307\n",
            "160 loss: 0.039010994\n",
            "161 loss: 0.039010715\n",
            "162 loss: 0.039010443\n",
            "163 loss: 0.039010193\n",
            "164 loss: 0.039009947\n",
            "165 loss: 0.03900973\n",
            "166 loss: 0.03900952\n",
            "167 loss: 0.03900932\n",
            "168 loss: 0.03900914\n",
            "169 loss: 0.03900897\n",
            "170 loss: 0.0390088\n",
            "171 loss: 0.039008655\n",
            "172 loss: 0.03900851\n",
            "173 loss: 0.03900838\n",
            "174 loss: 0.039008245\n",
            "175 loss: 0.039008126\n",
            "176 loss: 0.03900802\n",
            "177 loss: 0.039007913\n",
            "178 loss: 0.03900782\n",
            "179 loss: 0.039007723\n",
            "180 loss: 0.03900764\n",
            "181 loss: 0.039007556\n",
            "182 loss: 0.03900748\n",
            "183 loss: 0.039007403\n",
            "184 loss: 0.039007343\n",
            "185 loss: 0.03900728\n",
            "186 loss: 0.039007217\n",
            "187 loss: 0.039007165\n",
            "188 loss: 0.039007112\n",
            "189 loss: 0.03900706\n",
            "190 loss: 0.03900701\n",
            "191 loss: 0.039006975\n",
            "192 loss: 0.039006937\n",
            "193 loss: 0.039006896\n",
            "194 loss: 0.03900686\n",
            "195 loss: 0.039006826\n",
            "196 loss: 0.039006792\n",
            "197 loss: 0.039006766\n",
            "198 loss: 0.03900674\n",
            "199 loss: 0.03900671\n",
            "200 loss: 0.039006688\n",
            "201 loss: 0.039006665\n",
            "202 loss: 0.039006647\n",
            "203 loss: 0.039006624\n",
            "204 loss: 0.039006602\n",
            "205 loss: 0.039006587\n",
            "206 loss: 0.03900657\n",
            "207 loss: 0.039006554\n",
            "208 loss: 0.039006542\n",
            "209 loss: 0.03900652\n",
            "210 loss: 0.039006516\n",
            "211 loss: 0.0390065\n",
            "212 loss: 0.039006494\n",
            "213 loss: 0.039006483\n",
            "214 loss: 0.039006468\n",
            "215 loss: 0.039006457\n",
            "216 loss: 0.03900645\n",
            "217 loss: 0.039006446\n",
            "218 loss: 0.039006434\n",
            "219 loss: 0.039006427\n",
            "220 loss: 0.039006416\n",
            "221 loss: 0.039006412\n",
            "222 loss: 0.039006405\n",
            "223 loss: 0.0390064\n",
            "224 loss: 0.0390064\n",
            "225 loss: 0.03900639\n",
            "226 loss: 0.039006382\n",
            "227 loss: 0.03900638\n",
            "228 loss: 0.03900638\n",
            "229 loss: 0.03900637\n",
            "230 loss: 0.039006367\n",
            "231 loss: 0.039006367\n",
            "232 loss: 0.039006364\n",
            "233 loss: 0.039006356\n",
            "234 loss: 0.039006356\n",
            "235 loss: 0.039006356\n",
            "236 loss: 0.039006352\n",
            "237 loss: 0.03900635\n",
            "238 loss: 0.039006352\n",
            "239 loss: 0.03900634\n",
            "240 loss: 0.03900635\n",
            "241 loss: 0.039006345\n",
            "242 loss: 0.03900634\n",
            "243 loss: 0.039006338\n",
            "244 loss: 0.039006338\n",
            "245 loss: 0.039006338\n",
            "246 loss: 0.039006338\n",
            "247 loss: 0.039006334\n",
            "248 loss: 0.039006338\n",
            "249 loss: 0.039006334\n",
            "250 loss: 0.039006338\n",
            "251 loss: 0.039006326\n",
            "252 loss: 0.03900633\n",
            "253 loss: 0.039006326\n",
            "254 loss: 0.039006326\n",
            "255 loss: 0.039006326\n",
            "256 loss: 0.03900633\n",
            "257 loss: 0.039006323\n",
            "258 loss: 0.039006323\n",
            "259 loss: 0.039006323\n",
            "260 loss: 0.039006323\n",
            "261 loss: 0.03900633\n",
            "262 loss: 0.039006323\n",
            "263 loss: 0.039006323\n",
            "264 loss: 0.039006315\n",
            "265 loss: 0.039006323\n",
            "266 loss: 0.039006323\n",
            "267 loss: 0.039006323\n",
            "268 loss: 0.039006315\n",
            "269 loss: 0.03900632\n",
            "270 loss: 0.039006326\n",
            "271 loss: 0.039006326\n",
            "272 loss: 0.039006323\n",
            "273 loss: 0.039006308\n",
            "274 loss: 0.039006323\n",
            "275 loss: 0.039006323\n",
            "276 loss: 0.039006323\n",
            "277 loss: 0.039006323\n",
            "278 loss: 0.039006315\n",
            "279 loss: 0.039006315\n",
            "280 loss: 0.039006315\n",
            "281 loss: 0.03900632\n",
            "282 loss: 0.039006315\n",
            "283 loss: 0.039006323\n",
            "284 loss: 0.039006315\n",
            "285 loss: 0.03900632\n",
            "286 loss: 0.039006315\n",
            "287 loss: 0.039006315\n",
            "288 loss: 0.039006315\n",
            "289 loss: 0.03900632\n",
            "290 loss: 0.03900631\n",
            "291 loss: 0.03900632\n",
            "292 loss: 0.039006315\n",
            "293 loss: 0.039006315\n",
            "294 loss: 0.03900632\n",
            "295 loss: 0.039006315\n",
            "296 loss: 0.039006315\n",
            "297 loss: 0.039006315\n",
            "298 loss: 0.03900631\n",
            "299 loss: 0.03900632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbUucvyILdz4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25d8ab22-d869-4eec-81c0-685fec2b58d6"
      },
      "source": [
        "print('\\n Actual test: ')\n",
        "print(y_batch)\n",
        "\n",
        "print('\\n Predictions: ')\n",
        "print(y_pred_batch)\n",
        "\n",
        "print('\\n\\n Fitted Line')\n",
        "plt.scatter(x_batch, y_batch)\n",
        "plt.plot(x_batch, y_pred_batch, color='red')\n",
        "plt.xlim(0, 2)\n",
        "plt.ylim(0, 2)\n",
        "plt.savefig('plot.png')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Actual test: \n",
            "[0.52980277 0.41258307 0.45241571 0.62236906 0.59644671 0.79240309\n",
            " 1.07978312 0.91631331 0.94186522 1.14824486 0.92925492 0.44036601\n",
            " 1.22868697 1.01394212 0.89901598 1.19742439 0.71294873 1.30009119\n",
            " 1.11734204 0.68538775 1.01447937 1.24832364 0.82956658 0.78906473\n",
            " 0.85058058 1.24634104 1.4516984  0.88885619 1.06447383 1.5115615\n",
            " 1.54887679 1.48608265 1.43107493 1.606065   1.81484791 1.51526387\n",
            " 2.03944999 1.57129618 1.82806466 1.90269222 1.76806548 1.97787185\n",
            " 1.89622469 2.06737447 1.70054389 1.71456269 1.77402275 2.01283313\n",
            " 1.99340275 1.86583099 1.69157007 2.16659939 2.02021192 2.1888758\n",
            " 2.60940013 2.41244142 2.05530919 2.12589167 2.07200234 2.32696262\n",
            " 2.31265201 2.41963211 2.35907797 2.40532569 2.51879601 2.44462928\n",
            " 2.60080252 2.39820311 2.78344357 2.83928974 2.82345222 2.73949878\n",
            " 2.67587959 3.01097757 2.57991477 2.74290749 2.82699935 2.94287562\n",
            " 2.99956989 2.71178063 3.19894231 2.99378811 2.95985799 2.95215512\n",
            " 3.16649569 3.23115415 2.71599866 3.37568029 3.06017836 3.12979523\n",
            " 3.23367748 3.18557628 3.00628959 3.09967235 3.37889478 3.35218129\n",
            " 3.61803751 3.4556509  3.41057168 3.79279716]\n",
            "\n",
            " Predictions: \n",
            "[0.5330637  0.56321377 0.5933639  0.62351394 0.653664   0.6838141\n",
            " 0.71396416 0.7441142  0.77426434 0.8044144  0.83456445 0.86471456\n",
            " 0.8948647  0.92501473 0.9551648  0.98531485 1.0154649  1.045615\n",
            " 1.0757651  1.1059152  1.1360652  1.1662154  1.1963654  1.2265155\n",
            " 1.2566656  1.2868156  1.3169657  1.3471158  1.3772658  1.4074159\n",
            " 1.437566   1.467716   1.4978662  1.5280163  1.5581663  1.5883164\n",
            " 1.6184664  1.6486166  1.6787667  1.7089167  1.7390668  1.7692168\n",
            " 1.799367   1.8295169  1.8596671  1.8898172  1.9199672  1.9501173\n",
            " 1.9802675  2.0104175  2.0405674  2.0707176  2.1008677  2.1310177\n",
            " 2.1611679  2.191318   2.221468   2.251618   2.281768   2.3119183\n",
            " 2.3420684  2.3722184  2.4023683  2.4325185  2.4626687  2.4928186\n",
            " 2.5229688  2.5531187  2.583269   2.6134188  2.643569   2.6737192\n",
            " 2.703869   2.734019   2.7641692  2.7943194  2.8244696  2.8546195\n",
            " 2.8847697  2.9149196  2.9450698  2.9752197  3.00537    3.03552\n",
            " 3.0656703  3.09582    3.1259701  3.1561203  3.1862705  3.2164204\n",
            " 3.2465706  3.2767205  3.3068707  3.3370206  3.3671708  3.397321\n",
            " 3.4274712  3.457621   3.487771   3.5179212 ]\n",
            "\n",
            "\n",
            " Fitted Line\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}